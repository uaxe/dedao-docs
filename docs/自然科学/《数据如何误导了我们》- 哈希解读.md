## 《数据如何误导了我们》| 哈希解读

<img  src="https://piccdn.umiwi.com/uploader/image/ddarticle/2022063010/1778714274894521808/063010.png" width="2468"/>



你好，欢迎每天听本书，我是哈希。今天我要为你解读的这本书叫《数据如何误导了我们》。

人们经常说，当下我们已经进入了一个“数据时代”。的确，小到每个人自己的业务指标、健康指标、信用评分，大到宏观经济发展、全球气候变化，等等。我们会越发感觉到，自己对于这个世界的理解，越来越多地取决于自己看到的各种数据。而且，目前来看，在可见的未来，数据对我们的影响力还会持续增加。

然而，这本书提醒我们，很多数据其实并不像表面上那样客观、公正，反而常常会因为一些人为或非人为因素的干扰，对人们产生误导。

这本书的作者，是桑内·布劳博士。她是荷兰的一名计量经济学家，长时间致力于有关数据的采集、分析等方面的调查研究。在这本书里，她主要探讨了两方面的内容。首先是，为什么很多时候，一些看似客观的数据，其实是有误导性的？之后，还重点讲了，我们该怎么样避免被数据误导。我今天的解读，也将遵循原书的思路，围绕着这两部分展开。



首先我们进入第一部分，来说一说为什么很多时候，一些看似客观的数据，其实是有误导性的？

书里把数据研究的过程分为三个步骤，分别是数字标准化、数据采集，还有数据分析。咱们下面一个一个来说。你会发现，这里面的每一步，都存在着容易被忽视的陷阱。而正是这些陷阱，使得一些数据并不能客观反映事情的真相。

首先第一步，是数字标准化，指的是，给你的研究对象建立一个统一的测量标准。比如，如果我说，在锅里放一把米，这就不是一个标准化的说法，因为我抓一把米跟你抓一把米，重量不太可能一样；但如果我说，在锅里放200克的米，这就是标准化的说法了，因为它是放之四海通行的。

像距离、重量、人数这些物理世界中客观存在的事物，标准化起来是比较容易的。但是，随着人类社会的发展，我们开始试图去测量一些人为创造出来的概念，比如经济发展水平、智力水平、受欢迎程度、信用程度，等等。这个时候，很多问题就随之出现了。

首先，并不是所有概念都能转化为标准化的数字。比如，幸福，本身就是一种主观的感受，我们不可能把所有人的感受都拉到同一个量化维度里。

还有，把一个概念标准化的方式有很多种，但很难做到准确或全面。比如，最有名的例子，莫过于GDP了。我们知道，GDP，就是国内生产总值，它是一个经济体在一段时间内所制造的商品和提供的服务的市场价格的总和。当我们在说一个国家贫穷或者富有的时候，主要看的是人均GDP，它能体现一个国家民众的平均收入水平。

但是，多年来，反对把GDP作为衡量一国富裕程度的声音一直很多。理由包括，GDP没有考虑到那些发生在市场交易以外的创造价值的行为，没有考虑环境恶化等隐性成本，没有考虑收入分配，不能衡量人们对生活的真实感受，等等。人们也尝试提出过一些替代GDP的复合指标，比如“社会健康指数”“国民幸福指数”“人类发展指数”等等。但是，没有哪个指标能做到尽善尽美。

你可能也发现了，不管是GDP，还是“社会健康”“国民幸福”“人类发展”，其实都只是人们对于经济发展的不同定义而已；它们到底包含哪些衡量指标，取决于人们对于经济发展这个抽象概念的价值判断是什么。价值判断不同，采用的衡量指标也不同。这也是我们接下来要说的，数字标准化过程中的更深一层的问题，那就是，所有的、把抽象的概念标准化的过程，都是建立在人为的价值判断之上的。

我们再举一个例子。比如，拿智力这个概念来说，有一个很有名的智力测试工具，叫“韦氏智力测试”，是美国医学心理学家大卫•韦克斯勒主持编制的。这是世界上应用最广泛的智力测试之一，里面的题目主要涉及常识题、算术题、找不同、拼图案，等等，主要关注的是被试者的抽象思维能力。

但问题是，抽象思维能力强，就意味着智力水平高吗？并不一定。这只是智力测试设计者的一个价值判断而已。近一个世纪以来，也陆续有研究指出，以抽象思维能力来衡量智力，是有局限的。作者还说，如果换不同地区、不同种族的人来设计智力测试，那测试的内容可能完全不同，因为他们都会把自己认为重要的问题放进去。他还开玩笑地举了个例子，说，乌兹别克斯坦的人可能会问，怎么能更精准地射杀一只鸟，或者，冬天怎么更好地储存白菜，等等。而这些，我们大多数人可能都答不上来，那我们在他们看来，可能就得被归为智力障碍人群了。总之，作者想表达的是，无论是由谁来设计一个把抽象的概念标准化的方案，都只能代表一种特定的价值判断而已，并不意味着，这就是一个客观的选择。

好，到这里我们主要说的是数字标准化这个步骤中存在的问题，主要集中在那些人为创造出来的概念上。接下来我们说一说，数据收集这个步骤。

最典型的一种，以数据收集为主的社会研究方式，莫过于民意调查了。所以书里在这部分，也主要是以民意调查作为场景，来为我们讲述数据收集过程中的常见问题。

从本质上来看，民意调查其实就是从所有民众当中抽取一小部分作为样本，然后调查样本人群对某件事的看法，以此来判断民众对于这件事的整体意见。这个过程听起来很合理，就像我们在煲汤的时候，舀起一勺来尝咸度一样。

然而，在现实中，人们却经常发现，民意调查的结果，跟实际情况并不相符。比如，1948年的美国大选，胜出者是杜鲁门，这我们都知道。但其实，在大选结果出来之前的民意调查里，候选人杜威的支持率是超过杜鲁门的。选举结果公布前，当时的一些媒体对这个结果深信不疑，《芝加哥每日论坛报》甚至在大选结果出来的前一天晚上，就在报纸头版印上了“杜威击败了杜鲁门”这个大标题。

作者说，在2016年特朗普当选总统之前，也有许多媒体、专家曾根据民意调查的结果预测，特朗普会被希拉里打败。在大选结果出来之后的第二天，《纽约时报》发出了“灵魂拷问”，说：“他是怎么取得如此压倒性的胜利的？为什么之前几乎没有专家、没有民意调查、没有媒体预想过这种情况呢？”

除了关于总统大选的民意调查以外，我们在平时的生活中还能见到各种各样的民意调查。调查范围从公司到学校，再到更广泛的民众，调查内容从商业产品到政策措施，再到各种社会议题，不胜枚举。但是，在民意调查中获得高支持率的选项，却跟现实中的民众意愿相左的情况，也时有发生。那问题出在哪里呢？

作者认为，如果调查问卷的设计是合理的、中立的，问卷上的问题不具有误导性，那么主要的问题大概率是出现在对于样本人群的选择上。很多民意调查，调查的都不是真正的“民意”，只是某些特定群体的意愿。

像一些在公司内部，或者学校内部发放的问卷自然不用说了，即使是一份在《纽约时报》官网上发布的问卷调查，也并不是面向全社会民众的。事实上，它采集到的样本，只是那些可以使用互联网的，关注《纽约时报》的，并且愿意付出时间填写问卷的热心人士。还有一些在互联网小程序、更小的平台上发布的问卷，面向的受众就更小了。

科学研究中也经常出现类似的事：研究结论给出的是一般性的陈述，似乎是被科学论证过、放之四海皆准的，但产生这个结论的研究过程却排除了某些特定群体。比如，知名心理学家亨里奇就曾经说过：心理学研究中的样本是“怪异”的，因为他们（很多时候）都是来自西方的、受过教育的……具有民主意识的人；最终的心理学研究结果通常会用“全人类”一词概括，但事实上，研究采用的那些“怪异的”样本，跟其他群体之间，其实存在着极大的差异。

对于这类“样本局限性”问题，人们也在努力寻找解决方案。比如，改用随机抽样法，也就是，先把要调查的所有民众都列出来，然后从中随机筛选出要采访的样本，一一去联系；或者，改用配额抽样法，也就是，先把要调查的民众分为几个类型，比如，住在城市的成年男性、住在城市的成年女性、住在农村的未成年男性，等等，以此类推，然后，按照真实的人数比例来设计样本人数，再去全国各地寻找受访者。

不过，这些方法也并不完美。比如，随机抽样法，可能存在受访者失联或者拒绝参与调查的情况，那么最后被采访的那些人的代表性也会有所下降。而配额抽样法采用的人群分类，看似考虑周到，但事实上，分类的依据也只是研究设计者本人的主观判断，它假定人们的意见仅仅受到一些显性因素的影响，比如收入、性别和年龄，等等；但除了这些之外，人们的意见还可能会受到性格、梦想、儿时经历等其他因素的影响。目前，我们并不清楚影响人们意见的因素到底有哪几种。这也意味着，民调机构无法确定，到底要在哪些因素上对数据加以修正。

所以，作者提醒我们，要明白：人们采集到的数据永远不可能精准地反映现实；透过数据看现实，就像是透过磨砂玻璃看东西一样——你可以看到一个大致的轮廓，但永远都无法完全看清楚。

好，说完了数字标准化和数据采集，我们再来看看数据分析过程中可能出现的问题。首先一个被人们提到最多的问题就是，相关关系不是因果关系，这个你可能也听过。

针对这类问题，作者引用了一个有趣的例子。以前，有很多人观察到，一户人家屋顶上的鹳鸟巢穴数量越多，这家的孩子就越多；所以后来，民间有一种说法是，鹳鸟有送子的作用。但这种推导显然是欠妥的。

首先，这种观察可能本身就只是偶然事件。还可能是，存在另外一种因素在同时影响着鹳鸟的数量跟孩子的数量。比如，一个房子越大，房子里的孩子往往也就越多；而与此同时，这个房子上的烟囱数量也更多，于是就会吸引到更多的鹳鸟前来筑巢。也就是说，是房子的大小同时影响着鹳鸟的数量跟孩子的数量，并不是这两者之间真的存在因果关系。

类似的例子还有，一项研究表明，吸烟学生的成绩比不吸烟的差。那么，这能说明吸烟会影响学习成绩吗？并不能。因为这其中可能还存在别的因素，能同时影响到一个人的学习成绩好坏以及他是不是抽烟。比如在一些不好好学习的小混混当中，抽烟的行为就十分普遍，而同时，这些人的学习成绩也比较差。当然，这并不是唯一的可能性。作者说，如果一件事存在许多种合理的解释，那么我们就不能只按照自己的喜好，挑出其中的一种，然后坚持认为这种解释就代表了现实中的因果关系。

好，刚才我们说的是造成“伪因果关系”的两种情况：偶然事件，以及存在其他因素影响。还有第三种情况，那就是“反向因果”，也就是，把原因和结果搞反了。比如，下雨的时候，街上有很多人带着伞，但我们并不能说，是雨伞导致了下雨，这就是把原因和结果搞反了。

到这里，总结一下数据分析当中存在的第一个问题——相关关系并不代表因果关系。之所以会这样，是因为其中可能存在三种“伪因果关系”：一是纯属偶然，二是存在其他因素的影响，三是因果关系其实是反着的。

除了这个问题之外，数据分析中还有一个更重要的问题是，一切数据分析结果的背后，都存在着人为的选择——不管是有意识的，还是无意识的。比如，在学术界，往往只有那些发现了显著关联的研究成果才会被发表，而那些结论是“无关联”的研究大多被锁进了抽屉。所以，研究人员要想有成果发表，就得想方设法地从数据里找到事物之间的某种显著的关联。

比如，有一位名叫布莱恩·万辛克的前康奈尔大学教授，曾经做过一项研究，研究的结果表明，如果人们用美国电视节目“芝麻街”的卡通贴纸装饰苹果，小朋友们就会更愿意选择苹果，放弃不健康的甜食和饼干。这项研究结论被《纽约时报》等各大媒体广泛报道，万辛克本人也一时声名大噪。

但是后来，有人爆出了万辛克跟他的同事之间往来的电子邮件，从中人们发现，万辛克的研究实际上漏洞百出。比如有一回，万辛克团队里的一位研究员发邮件跟他说，自己刚刚分析了从一家自助餐厅那儿采集来的数据，却没发现能支撑结论的证据。万辛克回复说：“我做过的任何一项有趣的研究里，没有哪一项是马上就能看到显著结论的。”然后他给这个研究员出了个主意，说：“尽可能地把数据分成几个小组，再分析看看哪一组里，我们假设的关联是成立的。”

作者打趣说，这种数据分析方法，就像是，先假定吃果冻跟长痤疮有关系，然后挨个换不同颜色的果冻，用计量软件去分析它跟长痤疮之间有没有关联，绿色的不行就换黄色的，再不行就换粉色的，直到找出数据上有关联的那个颜色为止。然后就可以发表文章说“我发现某某颜色的果冻容易让人长痘”了。

像这样的数据分析方式，在研究中并不罕见。所以有些人会说，只要你拷打数据的时间足够长，总能找到两件事之间的关联。有一个叫泰勒·维根的数据分析师，为了帮人们看清这一点，会在一个专门的网站上发布各种看起来很疯狂的关联事件，还逐渐做出了名气。比如他发现，每年在泳池中溺水的人数，跟演员尼古拉斯·凯奇出演的电影数量有很强的正相关性；还有，每年的人均奶酪消费量，跟土木工程博士学位授予数量的相关性甚至高达95%以上，等等。这些都是真相吗？反正这位数据分析师自己是不信。



好，刚才我们讲的是，为什么很多时候，一些看似客观的数据，其实是有误导性的。过程中主要讲了在数据研究的三个主要步骤当中可能存在的问题。接下来我们再说一说，该怎么样避免被数据误导。

首先是，要警惕这个数据本身的产生过程。具体来说就是要问自己这么几个问题：

第一个，这个数据是由谁提供的？像一些小报可能会为了博人眼球，故意夸大一些数据结论。比如，他们可能会说，多食用某种食物，会让患某种疾病的风险翻倍，但如果你找来原本的研究结论，可能会发现，这个翻倍只是从0.1%上升到了0.2%。还有，如果你看到一个显示某项措施有利于利润增长的数据的时候，要看看，这个数据是不是由这项措施的建议者给出来的？看到一些显示红酒、咖啡或巧克力等消费品有益于健康的研究数据，也要看看，这个研究的赞助者里是不是就有这个消费品的某个制造商？等等。总之，如果数据提供方有可能因为这个数据而获益，那这个数据的真假就存疑了。

下面再来说说我们要问自己的第二个问题——这个数据描述的是不是一个人为创造出来的概念？随着经济社会的发展，人们不可避免地创造出了越来越多的抽象概念，来解释这个世界，比如经济增长、能力、智力、信用、幸福等等。但作者提醒我们，如果我们忘记了，这些概念只是人为创造出来的，而是把它们当做客观存在的事物，那就很危险了。因为这样的话，我们会很容易忽视了“抽象概念”跟“真实世界”之间的那道屏障；忽视了所有概念背后都隐含着人们的价值判断；忽视了并不是所有概念都能够被量化，量化的方式也不只有一种。所以，当我们看到一个数据，衡量的是一个人为创造出来的概念的时候，最多只能把它理解为，是真相的一个切面，而不能把它当作全部的真相。

第三个问题是，这个数据是怎么收集到的？比如，我们要关注，研究样本是怎么选取的——是随机抽取的吗，还是仅仅局限在某些特定的人群上？还有，研究的主题会不会让很多人觉得敏感，或者不愿意说真话？如果是的话，那收集到的数据当中，很可能有一部分没有反映真实的情况。

第四个问题是，这个数据是不是在告诉我们一种因果关系？如果是的话，就需要进一步思考一下，其中是不是存在我们在上一部分提到的那三种“伪因果关系”。比如，有可能是偶然事件，或者有其他因素在其中起作用，也有可能是把真正的因果关系弄反了。

好，刚才我们说的是，要警惕这个数据本身的产生过程。具体来说就是要问自己四个问题：

这个数据是由谁提供的？这个数据描述的是不是一个人为创造出来的概念？这个数据是怎么收集到的？这个数据是不是在告诉我们一种因果关系？可以看到，这些问题其实都是围绕着我们在上一部分当中讲过的，数据研究的主要步骤提出来的。作者说，如果在一份数据报道里找不到充足的依据来回答这些问题，那我们也没有必要把里面的数据太当回事。因为，假如研究人员没有勇气把他所使用的研究方法公之于众，那这项研究也不值得我们关注。

除了要警惕数据本身的产生过程之外，我们还需要警惕自己大脑的非理性。

具体是什么意思呢？我们以作者的一段亲身经历为例，展开来说一说。在过程中，你会看到，即使是像作者这样的、专门研究数据的专家，也可能会掉进大脑布下的非理性陷阱中。

有一天，作者读到了一篇关于酒精的研究，主要的数据结论是，如果你每天喝超过一杯酒，就会面临早死的风险。她非常生气，认为这个结论大概率是假的。这不仅是因为，她向来对各类研究数据保持怀疑，也有一部分是因为，她本身就很喜欢跟朋友一起聚会喝酒，不想被这个数据影响了兴致。

后来，有一个叫普拉萨德的医学研究人员在网上公开指出，这篇研究存在问题。比如，这项研究仅仅调查了很短一段时间内的酒精消费量；而且，尽管研究人员在爱喝啤酒的人中发现了更高的死亡风险，但在爱喝葡萄酒的人中却没有发现。他还分析说，与其说是酒精损害了人们的健康，还不如说是，爱喝啤酒的人群收入相对较低，因此健康状况也相对较差。

作者看到普拉萨德的这篇文章，心里很畅快，感觉自己可以放心地继续喝酒了。

但后来，她察觉到，自己的判断，其实严重地受到了个人感受的影响：她想喝酒的这个念头，主宰了她的判断过程。而当她再一次回头翻看普拉萨德在网上发的文字的时候，才发现，普拉萨德从来都没说过喝酒无害，他只是说这项研究本身有问题而已，是作者自己选择了一种符合自己理念的解读方式。这种情况在几乎所有人身上都会出现，我们都往往会以自己喜欢的方式，去解读我们所接收到的外部信息。

所以，警惕自己大脑的非理性，我们首先要做的就是，察觉到自己在看到某个数据时候的感受。如果感觉害怕、生气，不要急着把数据丢到一边；如果感觉开心、赞同，也不要就认定这是事实的真相。正确的做法是，再多点几下鼠标，寻找关于这件事的其他研究资料。

作者自己也是这样做的。在意识到自己被个人感受干扰了判断之后，她又去网上搜索了更多关于酒精的研究。综合多项研究结果，她发现，喝酒给身体带来的主要还是负面影响，在这一点上，专家们已经达成了共识。这也就是为什么，从2015年开始，作者所在国家——荷兰——的卫生委员会一直建议民众，每天最多只喝一杯酒。

作者认为，如果我们想避免被数据误导，“多点几下鼠标”应该是一项基本的自我要求。因为，就算一项研究进行得再好，要想仅仅靠它来证明一些什么，也是不够的。大多数的研究，都是在某个特定的时间点，对某个国家内的某个特定群组进行的。人们永远可以说，某项研究结果只是一个偶然事件，因此它的结论的适用范围是特定的。

而所谓“科学”，并不是单个的科学研究，而是所有科学研究的集合。如果对于某件事情，有很多不同背景的研究人员，采用了不同的研究方法去研究，最后大多得出了相似的结论，那么就可以算是一项“科学共识”。比如，吸烟有害身体健康、全球变暖会威胁人类的生存等等。作者认为，像这些科学共识，还是值得我们去重视的。



好，以上就是这本书里，我想跟你分享的重点内容。

人们常说，历史是一个任人打扮的小姑娘。而听完这本书之后，你可能会跟我产生相似的感受，那就是，数据，其实也像是一个任人打扮的小姑娘。由于存在各种人为或非人为因素的干扰，数据无法向我们展现出她真正的“素颜”。在今天的第一部分，我们把数据研究分为三个步骤，数字标准化、数据收集、数据分析，并分别讲了每个步骤当中可能存在哪些问题，以及这些问题会怎样对我们产生误导。而在第二部分，我们则是探讨了该怎么样避免被数据误导。主要就是记住两个“警惕”：

首先是警惕数据的产生过程。在看到一个数据的时候，记得在脑子里多画几个问号，想一想，这个数据是谁提供的，其中有没有利益关系？这个数据衡量的是不是一个人为创造出来的概念？数据研究采用的样本是不是某个特定的人群？研究结论是不是把相关关系当作了因果关系？等等。

另外，还要警惕我们大脑本身的非理性。这种非理性具体表现在，当我们在看到一个数据的时候，很可能会凭自己的感受来决定要不要信它，或是不自觉地把它往自己希望的地方解读，又或者是因为惰性，懒得再去多方查证，就直接盖棺定论了，等等。而对于大脑的这些非理性表现，我们的应对措施其实很简单，就是一句话——“多点几下鼠标”。

从本质上来看，“多点几下鼠标”其实是在要求我们，在探索世界真相的路上，永远要去拥抱不确定性。当你读到一个数据的时候，不要止步于此，而是应该继续调查。去搜索一下，那些持有跟这个数据相反意见的人是怎么说的；不要只读那些跟你观点一致的文章，还应该主动去读一读那些跟你的信念背道而驰的文章。

因为，任何数据研究，都只是现实世界的一张人工快照，即使没有布景、没有裁剪、没有滤镜、没有P图，也不能代表事物的全貌。如果我们只能依靠它们来了解这个世界，那么，起码也要去多找来一些不同角度、不同光线下拍摄的照片，对比着来看。并且，在过程中也要时刻谨记，这个世界上永远有某个角落，是没有被拍摄进来的；永远有某种视角，是人们可能尚未发现的。这就是我们所说的“拥抱不确定性”。

最后再多说几句。虽然，这本书的名字叫《数据如何误导了我们》，但作者在书里也说了，她写这本书的目的，并不是要让大家抵制数据，数据本身是无辜的，它只是我们理解现实的工具。一个工具能发挥怎样的作用，取决于人们怎么去使用它。所以，使用数据进行研究的人，需要避免因为直觉、认识偏差或利益关联，得出误导性的数据结论；而每天都会面对各种各样的数据结论的我们，也得擦亮眼睛，提高警惕；要记得，如果仅仅是满足于别人裁剪过的、打扮后的数据，而不去主动探求真相、主动拥抱更多的可能，那么你看到的世界，可能永远都只是别人希望你看到的样子。

以上就是这本书的精华内容，你可以点击音频下方的“文稿”，查收我们为你准备的全文和脑图。原书电子版已经为你附在最后，欢迎你进行拓展阅读。你还可以点击“红包分享”按钮，把这个音频免费分享给你的朋友。

恭喜你，又听完了一本书。



### 划重点

 1. 很多数据其实并不像表面上那样客观、公正，反而常常会因为一些人为或非人为因素的干扰，对人们产生误导。

 2. 数据研究分为三个步骤，数字标准化、数据收集、数据分析。每个步骤当中都存在容易被忽视的陷阱。

 3. 如何避免被数据误导：警惕数据的产生过程；警惕我们大脑本身的非理性。

 4. 从本质上来看，“多点几下鼠标”其实是在要求我们，在探索世界真相的路上，永远要去拥抱不确定性。





