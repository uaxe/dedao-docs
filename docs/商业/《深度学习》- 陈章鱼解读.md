## 《深度学习》| 陈章鱼解读

### 关于作者

本书作者特伦斯·谢诺夫斯基是全球人工智能十大科学家之一、深度学习先驱及奠基者，美国四大国家学院（国家科学院、国家医学院、国家工程院、国家艺术与科学学院）在世仅 3 位的「四院院士」之一，全球 AI 专业会议 NIPS 基金会主席。

作为神经网络的先驱，早在 1986 年，特伦斯就与杰弗里·辛顿共同发明了玻尔兹曼机，把神经网络带入到研究与应用的热潮，将深度学习从边缘课题变成了互联网科技公司仰赖的核心技术，实现了人工智能井喷式的发展。

### 关于本书

作为深度学习领域的通识作品，本书以恢弘的笔触，通过3个部分全景展现了深度学习的发展、演变与应用，首次以亲历者视角回溯了深度学习浪潮在过去60年间的发展脉络与人工智能的螺旋上升，并前瞻性地预测了智能时代的商业图景。

### 核心内容

人工智能今天有多么火爆，根本不需要我来为你介绍。AlphaGo、谷歌翻译、语音识别、无人驾驶，这些新技术都在告诉我们，人工智能正在改变这个世界。所以本期音频不把重点放到今天，而是放到人工智能的昨天和明天。

解读中先介绍了人工智能的发展史，你会发现，这个历史要比你想象中更加漫长和曲折。之后本书借助技术大牛的眼睛，共同展望人工智能的未来，你会发现，了解深度学习的原理之后，我们对于人工智能的未来，会有更清晰的想象。

<img  src="https://piccdn3.umiwi.com/img/202005/30/202005301732098429633499.jpg" width="1296"/>



你好，欢迎每天听本书，我是陈章鱼。今天为你解读的这本书叫《深度学习》，副标题《智能时代的核心驱动力量》。

这不是一本讲学习技巧的书，这里的「深度学习」是一个计算机术语。这个词你可能不熟悉，但是你一定听过人工智能。深度学习就是现在最热门的人工智能算法，通过模拟人脑的工作方式，让计算机真的变得智能。

可以说，深度学习就是人工智能的灵魂。

其实谈人工智能的书有很多，但是这本书很不一样。大多数讲人工智能的书，要么有很高的阅读门槛，只有计算机专业人士才能看懂。要么尽量不谈技术，关注点放在人工智能对外界的影响。而这本书是一本人工智能技术的通识著作，是写给门外人看的。从技术原理的角度去为我们梳理人工智能的发展史，展望人工智能的未来，可以让我们对人工智能有更透彻的理解。你要知道，把人工智能这样的技术给门外人讲明白，要比给同行讲明白更难，而这本书的作者，可以说是少有的几个合适人选之一。

这就要说到这本书的作者，特伦斯·谢诺夫斯基，谢诺夫斯基从事人工智能领域的研究将近 40 年。他是深度学习算法的奠基者，人工智能的先驱。

你会发现，这本书在讲述人工智能发展史的时候，那些人工智能研究领域的先驱，要么是谢诺夫斯基的老师，要么是他的朋友，甚至人工智能领域的一些重大突破，就是谢诺夫斯基自己推动的。所以，他是人工智能领域当之无愧的权威。

而且，谢诺夫斯基还是美国的「四院院士」，也就是同时担任国家科学院、国家医学院、国家工程院、国家艺术与科学学院的院士，这在美国科学界是极高的荣誉，目前在世的「四院院士」只有三位。

其实，人工智能今天有多么火爆，根本不需要我来为你介绍。AlphaGo、谷歌翻译、语音识别、无人 驾驶，这些新技术都在告诉我们，人工智能正在改变这个世界。所以我在解读这本书时，不把重点放到今天，而是放到人工智能的昨天和明天。

我们先来看一看，人工智能的发展史，你会发现，这个历史要比你想象中更加漫长和曲折。我们再借助技术大牛的眼睛，共同展望人工智能的未来，你会发现，了解深度学习的原理之后，我们对于人工智能的未来，会有更清晰的想象。



我们先来回顾一下人工智能的历史。了解人工智能的历史，你才能理解深度学习算法对人工智能的意义，才能明白为什么直到深度学习算法出现，人工智能才算拥有了灵魂？

眼看着今天人工智能技术如此火爆，你肯定不会想到，人工智能发展到今天，不到60年的时间，就至少经历了三次严重的危机。每一次危机都几乎让人工智能技术走进了死胡同。

第一次危机，在人们刚刚开始探索人工智能的时候就出现了。

人类是从什么时候开始研究人工智能的呢？目前科学界普遍认同，1956 年，马文·明斯基等四位美国科学家，共同发起了达特茅斯人工智能夏季研究计划，这个计划开启了人工智能领域的研究。

人们刚刚开始研究人工智能的时候，面前就有两个截然不同的方向，研究人工智能的先驱们，就像是金庸小说中的华山剑客，分成了两个派别。

一派我们可以称之为「设计派」。设计派认为，人工智能是可以自上而下设计出来的。只要给出明确的符号、规则和方法，编写程序输入计算机，就能让计算机拥有理性思考的能力。比如说，如果我们能找到一个准确定义，描述出来到底什么是苹果，之后计算机就能识别出这个世界上所有的苹果。

而另一派我们可以称之为「学习派」。学习派认为，在大部分实际问题中，我们其实很难找到「设计派」想要的那种明确的符号、规则和方法，所以我们可以借助大量的样本，让计算机通过不断学习的方式，慢慢拥有智能。

比如同样是苹果，学习派就倾向于让计算机识别大量的图片，相当于我们教计算机来认一认，这个是苹果，那个也是苹果，除了这些正面样本，还要让计算机识别反面样本，这个是香蕉，这个是橘子，在大量识别正面和反面的样本之后，计算机自己就能找到规律。

你会发现，后边说的这一派，也就是学习派，更像是我们人类学习和认识世界的过程。确实，学习派的核心理念，就是计算机通过学习和模仿人类大脑的工作原理，通过大量学习来理解事物，就能拥有人类的智能。

只可惜在人工智能的早期时代，大多数研究人工智能的先驱，不太关心人类大脑是如何工作的，他们更倾向于设计派。因为设计派的理念和之前计算机的研究更相符。以往计算机的功能，都是按照设计派的思路完成的。比如说实现计算功能，肯定不是给计算机一张九九乘法表，让计算机自己搞明白什么是乘法，而是把一套明确的计算规则编成程序，让计算机来执行。

所以大多数计算机科学家顺理成章地认为，在人工智能领域，设计派的思路也完全行得通。

没想到，他们马上就遇到了难题。

这个难题叫「积木问题」。顾名思义，就是教会机器人像小朋友一样堆积木。

「积木问题」的目标是编写一个能够理解命令的程序，比如「找到一个大块的黄色积木，把它放在红色积木上面」，然后把程序变成机器手臂可以完成的动作。这事儿看起来挺简单的，小朋友们都能做。可是教会机器人堆积木，其实比我们想象的要难很多，计算机科学家们发现，他们编写了一个庞大的程序，可是程序还是错误百出、频频崩溃。

看着程序崩溃，科学家们也挺崩溃。积木问题，这么一个看起来很简单的挑战，比任何人想象的都要难得多。更何况，积木已经是对现实世界的简化了，毕竟在现实世界中物体有不同的形状、大小和重量。就算解决了积木问题，想要通过编程完成一栋现实中大楼的建设，这中间还是有巨大的技术鸿沟。

于是「设计派」研究者心灰意冷，放弃了积木问题的研究。顺便说一句，「积木问题」直到 2016 年，才通过深度学习算法被解决。你也能看出来，60 年前的设计派研究者，确实是过于乐观了。

五十年代，还有类似的一些研究，比如教机器人打乒乓球，总之，研究者们发现，编写程序让计算机完成复杂计算、证明数学定理，这些其实都比较简单。反而是让计算机像人类一样，有视觉、有听觉、能顺畅地走路，这些看起来简单的问题，实际研究中都是困难重重。

经过了这样的挫折，学习派才开始慢慢被重视。学习派有自己的底气，因为任何人工智能领域的难题，自然界都已经通过进化解决了。不管是搭积木还是打乒乓球，我们的大脑已经有了一套高效处理的程序，所以，人工智能只要通过模仿人类学习的过程，就一定能找到一种行得通的算法。

所以计算机科学家们开始集中火力，努力找到一种可以模仿人类学习模式的算法。

1957年，康奈尔大学的弗兰克·罗森布拉特教授，第一个实现了突破，他发明了一种算法，叫做「感知器」。

感知器能完成的功能，就像是刚才我们提到的如何教计算机认识苹果。通过识别大量图片，哪些是苹果，哪些不是苹果，感知器就能自然形成一套自己的标准，认出哪些是苹果。

就在同一年，感知器算法就被用在了实际项目中，计算机科学家利用感知器算法，为美国军方完成了一个程序，让计算机识别有坦克的图片，训练一段时间后，计算机就能认出新图片中的坦克。这个成果被《纽约时报》报道，在美国引起轰动，人们开始看到人工智能解决现实问题的可能性。

虽然已经有了这样的突破，可是感知器算法距离真正的人工智能，其实还有很远的距离，因为科学家们发现，单独的感知器能够实现的功能是在太有限了。而且信息一旦变得复杂，计算机就会受到别的信息干扰。

比如识别坦克，科学家们发现，只能让计算机识别晴天之下的坦克，一旦照片里边有云彩，计算机就弄不明白到底该区分的是有云没云，还是有坦克没有坦克。

所以接下来的问题是，怎么让感知器算法能处理更复杂的问题呢？科学家们决定，还是向人类学习。

感知器模仿的是我们的神经元，而我们人类的思考，依靠的是无数神经元组成的神经网络。那么人工智能的研究者们开始思考，可不可以把感知器和感知器连接起来，组成更大的人工神经网络呢？

顺着这个思路，大家开始研究，不过很快就遇到了另一堵墙，而且这堵墙是一位人工智能研究领域的大神竖起来的。

这位大神就是我们刚才提到的马文·明斯基，你肯定还记得，开启人工智能研究的标志性事件，1956年达特茅斯人工智能夏季研究计划，就是马文·明斯基发起的，所以在大家眼中，明斯基就是「人工智能之父」。

但是在1969年，明斯基出版了一本书，书名就叫《感知器》。书中的具体技术细节，我就不在这里展开了，最关键的，是明斯基在书中给出了几条论断：单个的感知器，只能解决很有限的问题。要解决更复杂的问题，必须要把更多感知器连接起来，组成人工神经网络。

到这里，你应该觉得还很正常，这和我们刚才想得差不多啊，但是明斯基在《感知器》这本书里还给出一个结论，那就是，我们没法找到一种可行的算法，训练人工神经网络。

这就相当于，爱迪生发表一篇论文，告诉世界，我们发明了电灯，但是在更复杂的领域，我们根本无法驾驭电力，不止现在不行，未来也不行。

人工智能之父明斯基做出的悲观判断，让整整一代人工智能研究者，都对人工神经网络望而却步。这让人工智能的研究，陷入第二次危机。

好在，仍然有一小拨儿计算机科学家还在坚持不懈地研究，尝试找到能驾驭人工神经网络的算法。就连明斯基自己，也没有放弃在人工智能领域的探索。最终在 16 年后，也就是 1985 年，研究者们看到了希望。

这一次的破局者，正是本书的作者特伦斯·谢诺夫斯基。

谢诺夫斯基和另一个人工智能领域的专家杰弗里·辛顿，共同提出了一种算法，可以让很多感知器共同组成一个人工神经网络。这个算法叫做「玻尔兹曼机」。

玻尔兹曼机的算法原理有些复杂，我就不在这里为你展开讲了。不过这个算法的出现，可以说有石破天惊的意义。因为它证明了计算机科学家完全可以找到一种算法，让感知器连接起来组成人工神经网络，来处理更多更复杂的问题，彻底打破了明斯基在16年前的预言。

所以回头来看，明斯基当年犯的一个错误，把无数人工智能领域的研究者给吓住了，让人工智能的发展速度，放慢了十多年。

书中还讲了一个八卦：2006 年，谢诺夫斯基在一个学术会议上遇到明斯基，他很不客气地问明斯基：你承认你是上世纪 70 年代，制造神经网络萧条的魔鬼吗？明斯基也是一个实事求是的人，犹豫片刻之后，他承认，确实是他制造了当年神经网络的萧条。

在 1986 年，另一位计算机科学家大卫·鲁姆哈特又提出了「误差反向传播」算法，这个算法比玻尔兹曼机更简单、更有效率，简单来说，就是鲁姆哈特找到了感知器和感知器之间沟通的语言。鲁姆哈特关于「误差反向传播」算法的论文，到今天为止，至少被其他研究论文引用过4 万次。你要知道，一篇论文如果被引用超过 100 次，就算是在领域内产生过巨大反响，鲁姆哈特这篇论文，可以说是奠定了人工智能领域的基础。

找到了感知器和感知器之间沟通的方式，计算机科学家终于可以组建更庞大的人工神经网络，来处理更多更复杂的问题了。

人工智能的第二次浪潮也开始到来。上一次，感知器的发明，只是证明人工智能能够解决一些问题，所以更多地是让学术界兴奋。而这一次，人工神经网络出现，证明人工智能有可能解决极多的问题，所以这一次浪潮，也引起了商业投资人和普通民众的关注。

今天我们所有关于人工智能的想象，什么智能翻译、语音识别、无人驾驶、智能医疗，其实在 80 年代的那波人工智能浪潮中，都经过尝试，那时的人工智能项目，就成为科技投资人最追捧的项目。

一时之间，人工神经网络成为大家热议的名词，在 1991 年的电影《终结者 2》中，施瓦辛格扮演的机器人有一句台词：「我的 CPU 是一个神经网络处理器，一个会学习的计算机。」

可是这股浪潮，也仅仅持续了不到十年，到了 1995 年前后，大家又开始对人工智能失去了信心。

这一次遇到的问题是，训练人工智能太慢了，有一位国内的人工智能研究者回忆，一直到 1998 年，他做研究生的时候，在当时的电脑上运行人工智能程序，单元不敢超过 20 个。你可以把单元想象成大脑的神经元，你要知道，人类大脑的神经元，数量是以亿作为单位的。

此时的人工智能，是个算法上可行，实际中无力的领域。于是，又一次遇到了寒冬。

人工智能领域的研究者除了继续优化算法，更多的时间只能等待，等待计算机的算力快速发展。

从1995年开始的这次人工智能的寒冬，恰恰是计算机大规模发展的时代的，你可能听说过，芯片业有一个特别有名的规律，叫「摩尔定律」，就是每隔两年，芯片内晶体管的数量增加一倍，简单来说，就是芯片的运算能力增加一倍。 

这种指数级增长，随着时间的积累会很可怕。两年翻一倍，十年之后就是 32 倍。 

从 20 世纪 70 年代，一直到现在，「摩尔定律」持续了将近 50 年的时间。这是什么概念呢？今天的同样大小的芯片，比当年的运算能力至少高出 100 万倍。

这一次，人工智能的春天终于来了。算法已经成熟，计算机能力也不再那么孱弱，人工智能领域的研究者，终于可以组建大规模的人工神经网络，而让人工神经网络发挥出魔法的，就是深度学习算法。

深度学习中的深度，指的是算法中的隐藏单元。你把一个人工智能想象成我们人类，我们有耳朵可以听声，有嘴巴可以发声，除此之外，大脑中还有无数的神经元，它们虽然无法发出声音，但是它们在为我们的听和说工作，这些神经元，相当于算法中的隐藏单元。这些隐藏单元越多，人工智能就能处理越复杂的任务。

比如谷歌开发的 Google Brain 项目，用来进行语音识别和图像搜索，他们构建的人工神经网络，就有超过 10 亿个节点。

从 2012 年开始，在这样强大的算力支持下，在深度学习算法的带领之下，人工智能迎来了第三次浪潮，也就是今天我们正在经历这股人工智能浪潮。



梳理完人工智能的过去，我们转过头，来看看人工智能的未来。

听完人工智能的历史，你会发现，人工智能并不是我们想象中那样一帆风顺、高歌猛进。认真算一算日子，人工智能的低谷期，要其实要比受重视的日子还要长。

1956年到1969年，人工智能兴起了12年，之后走进低谷17年。1986年到1995年，人工智能又兴起了10年，之后又走进低谷17年。

那么一个迫在眉睫的问题就是，从2012年开始的人工智能又一波浪潮，也会在10年之后陷入低谷吗？下一个人工智能危机，会出现吗？

谢诺夫斯基做出了几种猜想。

猜想一，根据目前的人工智能的发展来看，下一次人工智能的危机，很有可能问题不会出在计算机那边，而是出现在我们人类这里。

为什么这么说呢？因为人类可能会越来越看不懂深度学习。

有一位国内的人工智能专家做了一个比喻，深度学习越来越像是「炼丹」。我们知道计算机能给我们一个好结果，可是这样的结果是怎么出来的，越来越难以解释。

既然连解释都很难，想要调整参数、定向优化就更难。

目前来看，还没有太大的问题，就像AlphaGo与人类对弈时那匪夷所思的一手棋，虽然连围棋高手当时都很难解释，但是实际的结果证明那样是更好的选择，大家可以通过复盘再去学习它背后的思路。

可是当人工智能覆盖到更多的领域，比如医疗领域，无人驾驶，那么当计算机给出一条让我们觉得匪夷所思的指令时，我们敢相信计算机吗？

那个时候，恐怕我们在没有找到合理的解释之前，不敢轻易让计算机做主。因为我们无法确定，那匪夷所思的指令到底是计算错误，还是真的有我们想不到的更好选择。

如果一旦是错误，那可能会对别人的生命造成损伤。

这可能是人工智能的下一次危机，当我们越来越不理解人工智能的结果时，我们就不敢将人工智能放到更多的领域。

第二种猜想，人工智能的下一个瓶颈，可能是因为我们对自己缺乏了解。

回头看人工智能的发展，我们对计算机的设计，越来越模仿我们人类的大脑，可是直到今天，其实我们对于自己的大脑，真的没有那么了解。

虽然计算机已经如此强大，但是大脑的计算能力和精巧设计，仍然远超计算机。

举个例子，英国皇家学院院士，伦敦大学的著名神经科学家曾带领科研组做过实验，人类大脑执行运算的次数是每秒 4 千 4 百亿次。而大脑的功率，大概 20 瓦上下，和家里的台灯能耗差不多。而我们一台普通的家用电脑，功率也要在 300 瓦左右，更不要说超级计算机，它们的功率，都是惊人的天文数字。

大脑不止硬件上特别省电，在算法上，似乎也比人工智能要高明许多。谢诺夫斯基就在书中总结出一个「100步法则」。

也就是，人工智能中使用的算法在运行了数十亿个步骤之后，却常常得不出一个正确的结论，而大脑只需要经历大约100个步骤，通常就会得出一个正确的结论。

人工智能想要继续发展，看来还要继续像人类学习，可是我们对于大脑的工作原理，目前的认识还相当浅。

如果在考虑上机器人领域，那人工智能领域的问题就更多了，目前机器人的发展远远落后于人工智能，就是因为模仿人类的身体比模仿大脑更加复杂。

所以，如果我们还是不能更透彻地了解自己的大脑和身体是如何工作的，也就谈不上让计算机来模仿了。这是谢诺夫斯基的第二个猜想，人工智能领域的瓶颈，可能不是来自于人们对于计算机的研究，反而是来自于人们对于脑科学的研究。

谢诺夫斯基的第三种猜想，人工智能的瓶颈，可能来自于芯片领域。

前边我们提到，人工智能的快速发展，离不开计算机算力的持续提升，可以说是摩尔定律在推动着人工智能前进。可是有计算机科学家预言，摩尔定律已经快要失效了。

摩尔定律的核心思路，是让同样大小的芯片，里边的晶体管数量增加，这就要求晶体管必须越做越小，计算机算力成倍地提升，晶体管就必须成倍地缩小，可是这种缩小是有限度的，物理定律约束了它的极限。计算机芯片正在快速逼近这个极限。

除非计算机科学家设计一种全新的芯片结构，甚至找到一种新的物理材料，否则摩尔定律失效的那一天，就是人工智能遇到瓶颈的时候。今天的人工智能虽然已经能模拟上亿个神经元，但是和真正的人脑相比，规模还仅仅是百分之一，如果计算机算力不能继续成倍地增长，那么人工智能就拥有无法达到人脑的深度。

前边就是人工智能未来危机的三种猜想，我们对人工智能的理解不足，我们对于脑科学的理解不足，芯片技术的发展受限，都有可能成为人工智能领域接下来遇到的挑战。



到这里，这本《深度学习》其中精华的部分，我就为你解读完了。

我有一个感受，那就是一门技术的兴起，所经历的质疑与挫折，都比我们想象中要多。同样，一门技术在寒冬的时候，到底有多久才能遇到春天，也往往和我们想象得不一样。

这一点，在人工智能领域尤为明显。

IBM 的总裁托马斯·沃森在1943年说过一句话：「我觉得全世界也许能卖出 5 台计算机」。

同样，人工智能之父明斯基也说过两句很打脸的话，1970 年他说：「三到八年后，我们就会有一个机器，达到普通人类的智能水平。」可是就在那年，人工智能渐渐走进第二次冬天。

2003年明斯基说：「1970年代以来，人工智能就脑死亡了。」可是不到10年时间，人工智能开始走向最辉煌的时代。

即使是人工智能之父，对未来的预测，也常常是错误的。

我相信人工智能的未来也不会是一帆风顺，很有可能还是会起起伏伏。也许人工智能的发展永远无法摆脱周期律，永远是热闹十几年，冷清十几年。

而回顾人工智能每一次遇到的危机，你会发现，每一次解决的方案，都是那些在寒冬中还没有放弃希望的科学家，他们探索出来的。

所以看一门技术的发展，与其看风口到来之时，有多少人为之疯狂，不如看盛宴零落之后，还有多少人在继续坚持。

那些人，可能才是智能时代的核心驱动力量。




撰稿、转述：陈章鱼
脑图：摩西脑图工作室

### 划重点

 1. 人工智能领域的研究从1956年至今，一共遭遇了三次危机，三次危机之后，也迎来了三次浪潮，我们现在正在经历人工智能的第三次浪潮；

 2. 人工智能领域的研究者一开始分成两派：设计派和学习派，科学家们逐渐发现，通过模仿人类大脑学习的过程，更能解决人工智能领域的问题；

 3. 我们对人工智能的理解不足，对于脑科学的理解不足，芯片技术的发展受限，都有可能成为人工智能领域接下来遇到的挑战。

