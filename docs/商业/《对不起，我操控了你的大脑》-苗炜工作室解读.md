## 《对不起，我操控了你的大脑》｜苗炜工作室解读

<img  src="https://piccdn.umiwi.com/uploader/image/ddarticle/2022042215/1772331836454735720/042215.jpeg" width="2481"/>



你好，欢迎每天听本书。今天为你解读的书是《对不起，我操控了你的大脑》。

本书的作者叫克里斯托弗·怀利。2013年，他参与创办了一家数据分析公司，名叫剑桥分析。他担任研发总监。不久后，他因为无法容忍公司的龌龊行为就退出了。后来，怀利跟记者合作揭露了公司做的事：剑桥分析利用数据，干扰了美国大选和英国脱欧的投票；利用开发出来的心理战工具，操控数百万民众的意见。媒体曝光后，客户跑光了，剑桥分析公司宣布启动破产程序。

用工具操控民众的意见？听起来有点儿玄乎。但在一定程度上，人都会受到认知偏差的影响，很难有人是纯粹的理性思考者。举个例子，假设有一天上班路上，有人拦住你，问，“你幸福吗？”你可能会回答说，“幸福”。但如果他拦住你，先问“你最近两年是不是长胖了”，或者“你的大学同学是不是比你挣钱多”，然后再问你，“你幸福吗？”这个时候，你回答说“幸福”的概率就会降低。这个人用体重和金钱影响了你对自己人生的认知，尽管你什么都没有改变。你幸福还是不幸福，答案取决于哪个信息最先出现在你的思维过程中。在心理学中，这个现象叫作“启动”，就是说，先前的信息对你随后的认知，产生了影响，正向的或者负向的。

剑桥分析公司就是这样“启动”他人的。这家公司的心理学家、数据工程师、老板和投资人，都在琢磨怎么去“启动”一个人，都在研究先传递哪些信息，可以影响一个人的感受、信念和行为。这其实就是书名里的“操控”，把一个人当成数据，再把这些数据做大，剑桥分析公司就能化数据为武器。

剑桥分析公司从社交媒体脸书（后来改名叫Meta）那里，弄来大量用户数据，还在中北美洲和非洲，进行操控他人头脑的项目。通过这本书，我们能够了解这家公司怎么操控他人头脑，并从中获得警醒。比如，看到他们如何给文化做定量分析，如何激发人们的愤怒，如何利用人们的认知偏差，如何激活人内心中恶的一面，我们会意识到，网络平台对普通人的了解，远远超出人们的想象。人们常常以为是自己在网络中作出各种决定，但他们并不知道网络背后藏着一双隐形的手在操控。这也正是作者怀利写这本书的目的，他揭露剑桥分析公司的所作所为，就是想要拉响警报，让人们了解，互联网巨头的算法正在操控人的思想，人们的身份和行为成为数据交易中的商品。

这本书不仅讲述了剑桥分析“操控他人”的想法，还讲述了他们怎样利用它成立一家创业公司、获得投资，又作出了哪些业绩。怀利在书里描述了剑桥分析的邪恶性，他相信，剑桥分析的所作所为影响了2016年的美国大选，也在英国脱欧的投票中做了手脚，但他其实没有十足的证据，他对剑桥分析的指控也并不是百分之百可靠。不过，读这本书，能帮助我们认识到，剑桥分析的技术专家、心理学家，还有资本家，是如何把每一个活生生的人，当成数据来思考和处理的。

好，我对这本书的解读分成两个部分。第一部分，我们来看看怀利的成长之路，剑桥分析公司从创业到破产的过程。第二部分，我们来看看，剑桥分析到底琢磨出了哪些套路来控制他人的大脑。怀利披露这些套路，其实是在提醒人们：人很容易被算法操控，偏见可能会在不知不觉中被放大，甚至会被激发出黑暗人格。避免被算法操控，首先要做的就是了解它如何运作。



好，我们进入第一部分。

怀利是个加拿大人，12岁时，因为生病坐进了轮椅。13岁左右，他开始制作网页，建网站，学编程。稍大一点儿，他开始混迹黑客社区。他从黑客理念中学到——任何系统，不论是一台电脑，还是一个网络，都有可能暴露自己的弱点和缺陷。作为黑客，他知道每一个系统都有弱点在等着被人利用。

经过治疗后，怀利摆脱了轮椅，还在加拿大一个政党那里得到一份技术员的工作。那时候社交媒体正在兴起，美国总统的竞选工作会大量使用它们，怀利就被派去美国考察学习。

有一家美国公司负责收集数据，鼓励选民投票。怀利去那里考察了一番，开始学习使用一些基础软件包做数据处理。他当时相信科技向善，数据是一种向善的力量，能鼓励那些被遗忘的人去参与政治。

考察结束后，他为加拿大那个政党写了一份报告，里面讲的都是技术。但加拿大那个政党对报告没啥兴趣，怀利就决定离开，到伦敦政治经济学院读法律。

2010年夏天，21岁的怀利在伦敦租了一间公寓，念书，享受城市生活。而后，他接到一个电话，是英国一个政党——自由民主党打来的。他们听说怀利研究过竞选和数据库，就想听一听这个小伙子有何高见。

自由民主党的办公室里贴着一张宣传标语——“无人当被贫穷、无知或从众盲从奴役”，这句口号很对怀利的胃口，所以他又开始为这里工作。怀利一边上学，一边工作，还结交了各种朋友。他认识了一个剑桥大学心理学博士，博士建议说，如果你想更深入地研究人格和投票行为的关系，就该用到人格五因素模型。这个模型把人格分成五个维度，然后评分。五个维度分别是开放性、尽责性、外向性、宜人性和神经质。简单来说，尽责性得分高的人，学习成绩可能更好，开放性得分高的人更可能成为创意人士。听上去很简单，但怀利说，人格五因素模型在预测选民行为方面，可以发挥极大的作用。后来，这个模型成为剑桥分析公司的核心理念。

几年后，有人给怀利推荐了一份工作，他就去这家名叫SCL的公司应聘。SCL集团正是后来剑桥分析的母公司，而面试他的人名叫亚历山大·尼克斯，是后来剑桥分析的总裁。

面试那天，尼克斯向怀利介绍，公司的大多数业务都和英国军方、情报部门有关。英国政府不好公开进行的活动，会交给这家私营公司来干。SCL集团会在东欧进行对抗俄罗斯的宣传，还在拉丁美洲开展反毒品计划，煽动那些种古柯的农民对抗毒枭。怀利对尼克斯说，现在这套心理战做法，跟撒传单没什么两样，公司要想发展，就应该获得更准确的数据，构建算法，瞄准更确定的目标人群。

当时，SCL集团正在做一个案例研究，他们把特立尼达和多巴哥共和国当成目标。这个加勒比小国有130万人口，当地政府希望能预防犯罪，于是允许SCL读取这里的人口普查数据，电信公司也允许SCL能实时访问当地任何一个人的数据。SCL选取一个IP地址，就能发现这个人在网上的踪迹。

尼克斯当时在SCL公司负责操控加勒比海地区、非洲和南亚一些国家的选举。他是个富二代，其实不需要上班，但他喜欢这里的工作，这给他一种高高在上的操控感。怀利看不上尼克斯的傲慢和势利，也看不上SCL缺乏道德感的商业行为，但他相信SCL仍然有许多好人，他所做的项目能够造福世界，于是还是留在这里，和心理学家、数据工程师一起工作，监控他人，影响和改变他人的思想。

2013年10月，怀利见到了一个叫史蒂夫·班农的美国人，向他演示SCL在特立尼达和多巴哥的项目，班农后来参与了美国总统的竞选工作，还进入白宫担任顾问。怀利调出地图，地图上逐渐出现一层荧光点，每个亮点都是一个活生生的人，上面有他们的基本数据。怀利往上添加一个信息层，亮点就会变多，向外扩展，每个人的网络浏览历史就出现了。

班农问怀利，你们整的这些东西能改变文化吗？怀利说，我们要做的是对文化进行定量分析，对文化进行测量；通过追踪、测量、分析，就可以知道我们是否正在改变文化。比如，可以先假定意大利人都比较外向，然后通过网络监控，分析意大利用户的消费习惯、行为模式，这样就能识别出最外向的意大利人，列出来一份外向排名的名单。如果想让他们变得不那么外向，就要追踪他们，向他们传播定向的信息，一点一点地削弱外向人格。怀利还向班农解释了，什么是心理学上的“启动”，要想改变文化，就要找到那些最容易被“启动”的人，然后再逐渐扩散。

班农看完怀利的演示之后，很想让怀利把这套监控做法用到美国人身上。于是，见完班农后，怀利开始收集美国弗吉尼亚州居民的信息。他从一些私营机构那里购买数据，也会搜罗持枪证、钓鱼证等个人资料。班农还对怀利、尼克斯等人许诺，有个大金主对他们的做法感兴趣，也许会投资2000万美元。

当时，SCL的年度预算也不过700万美元到1000万美元，如果有2000万美元的投资，就能大展手脚。这个金主叫默瑟，是个内向的工程师，有计算机博士学位，曾经在IBM工作过，后来他专心把技术手段都用在了挣钱上。

2013年11月，尼克斯带着怀利等人飞赴纽约，面见投资人默瑟。在默瑟的家庭聚会上，尼克斯和怀利讲述了SCL的发展策略。默瑟听得非常认真，在他的构想中，如果能在电脑上重建人类社会，输入的都是真人数据，那么就可以预测社会及市场的动向。如果能创建出这样一个人工社会，那就拥有了世界上最强大的市场情报工具。

班农和默瑟的想法不尽相同，默瑟想赚钱，班农想用在政治上。但两个人有相同的诉求，那就是用上帝视角来看待脸书、看待人们在网上的行为，以及他们在现实中的行为。

聚会结束后，默瑟决定投资SCL，他出资1500万美元，占股90%。SCL出知识产权，占股10%。他们一起建立了“剑桥分析”公司。公司名里有“剑桥”，是因为“剑桥”听上去有知识分子气息，而班农以知识分子自居。尼克斯曾向班农撒谎，说SCL集团在剑桥有办公室，但实际上这个办公室只是临时租用的，里面的职员也都是临时雇来演戏的。尼克斯搞定了班农，班农搞定了投资，两个人分别出任剑桥分析公司的总裁和副总裁。

怀利的心理学博士朋友，也进入剑桥分析公司工作，还介绍了几位剑桥心理学专业的教授，他们后来都参与了剑桥分析的工作。其中有两位教授曾经做过一个小程序叫“我的人格”，供社交媒体的用户下载。这个小程序就是做心理测验的，用户完成测试之后能获得一份自己的人格画像。人们热衷于做这些小测试，但做完就忘了。人们通常也不太在意，自己在网上做的测验、发表的评论，或者给谁点了个赞，到底意味着什么。

但这些行为意味着每个人都可以被当作数据对待。2015年的一项研究表明，一个计算机模型可以通过脸书上的点赞数据，精准地预测人的行为。只要拿到某个人10个点赞数据，电脑模型对这个人的行为预测，会比他的同事还精准。如果有了一个人的150个点赞数据，预测准确率会比他的家人还高。如果有300个点赞数据，这个模型对他的了解，会比他的配偶还要高。这其实并不难理解，家人、朋友、同事，一般只能看到自己生活的某一方面。我们的某些行为会避开他们，不想受到他人关系的控制。所以，电脑在判断人格方面是有一定优势的。做市场营销或者心理评估的，都很依赖把人当成数据来处理。

把人当成数据来处理，这个趋势会改变个人隐私的概念。拿“我的人格”这个程序来说，一个用户下载、用了这个程序，程序开发者就能掌握这个人及其好友的个人资料。脸书用户的平均好友数量超过了150个，如果1000个人用了这个程序，开发者就能拿到15万人的个人资料，200万人下载了这个程序，开发者就能拿到3亿份个人资料。就算去掉其中重合的人，那也是一个庞大的数据集。此前，SCL用过的最大数据集，是特立尼达和多巴哥130万人的个人档案。当剑桥分析公司获得投资之后，他们利用小程序和第三方机构，从脸书那里拿到了几千万份美国用户的数据集。

当时，尼日利亚有一些富翁会聘用剑桥分析来影响当地的大选。富翁们担心，如果一个名叫布哈里的穆斯林候选人在大选中获胜，就会把石油勘探权收为国有，缩减这些富豪的财源。为了毁掉布哈里，剑桥分析公司侵入了相关的邮箱和医院病历，挖掘对布哈里不利的信息。他们还向特定人群散播病毒小视频。视频中宣扬说，如果布哈里当选，就会在尼日利亚实施伊斯兰教法，而后播放了一连串惊悚的画面。怀利认为，公司的行为太龌龊了，他实在忍受不了公司的所作所为，就离职了。

2018年3月，《卫报》和《纽约时报》报道说，剑桥分析公司未经授权，访问了5000万份脸书用户的个人资料，还通过数据分析有针对性地影响选民，协助特朗普赢得2016年美国总统大选。这份报道其实准备了很久，记者在怀利的协助下，揭露了剑桥分析公司的所作所为。很快，剑桥分析和SCL宣布启动破产程序，脸书的CEO扎克伯格接受美国国会的问询。最终，脸书交纳了50亿左右美元的罚款。而怀利，被脸书和其旗下的照片墙软件(Instagram)列入黑名单，不许他使用这两种社交媒体。

这就是“剑桥分析”这家公司从创业到破产的过程。



好，我们进入第二部分，来看看，剑桥分析琢磨出了哪些控制他人大脑的套路。

剑桥分析到底在多大程度上操控了别人的大脑？到底是否影响了2016年的美国大选？剑桥分析的总裁尼克斯大肆宣扬自己公司的能耐，曾经向记者假扮的客户炫耀说，特朗普赢得选举，剑桥分析功不可没。但是，谁也无法证实他们真的能改变别人的思想，操控了大选。技术专家对此也有不同的认识。有一本书叫《被算法操控的生活》，作者说，脸书的研究显示，跟那些没有接触太多负面新闻的人相比，被负面新闻狂轰滥炸的人，每个月会倾向于多发一个带负面色彩的词，这种影响实际上微不足道。

我们回到今天这本书。怀利在2014年11月离开了剑桥分析，他有一些前同事的确为美国大选和英国脱欧的项目工作过，但怀利并没有确凿的证据，能让尼克斯或者班农受到惩罚。然而，怀利对剑桥分析的指控，对我们每个人都有警醒之处。一帮心理学家和数据专家，琢磨怎么激发、利用互联网上的黑暗面，怎么利用社交媒体和假新闻操控他人。

接下来，我们来看看他们是怎么想的。

剑桥分析要做的第一条是，“把政治正确界定为一种身份威胁”。

剑桥分析注意到，许多美国人都觉得自己困居柜中。怀利用这个词来描述很多白人男子的感受。这个群体，特别是年纪较大的那部分人，从小就被灌输了一套观念，认为自己天生享有一定的社会特权。

过去，他们说话不必节制，可以表现出自己的种族主义倾向和厌女倾向。但社会变化了，在工作场所和女性信口调情，可能会被投诉、失去工作，他们也不能张口就说黑人都如何低劣。这个群体不得不约束自己的语言，不断纠正自己在公众面前的表现。有一些年轻的白人男子还组成了“非自愿独身者社区”，他们找不到高薪工作。对他们来说，受欢迎的男性形象越来越高不可及，要高薪、要身材管理得好、要尊重女性，这让他们内心充满愤怒。

班农掌控剑桥分析之后，他要干的一件事，就是把这些人心中的仇恨和愤怒给勾出来。认为自己享有社会特权的白人男子，总会高估别人对自己的关注程度，所以，要想让他们感受到社交不适，就要向他们传播这样的信息——“想象有一天，你身在美国，但没有一个美国人的名字你念得出来。这个名字的发音难度有多大？你记不记得有人曾因念错了某个种族的名字而受到嘲笑？”

剑桥分析要给这些人建立一个信念——种族关系是一场零和博弈，少数族裔拿走的东西越多，你能拿到的就越少。别人要是主张政治正确，你就无法发声。

把政治正确界定为一种身份威胁，就会催发一种“飞去来器效应”，就是说，接触到跟自己意见相左的人之后，我的偏见和信念反而会加强。比如，一个名人发表了种族主义或厌女言论，就会获得支持者，当媒体抨击这个名人的言论，这些批评会更加坚定支持者的决心，他们把这种批评内化为对自己身份的威胁。

剑桥分析要做的第二条是“强化认知偏差”。

有一个心理学术语叫“公正世界假设”。听起来不错，但它其实是一种认知偏差。一个人相信自己生活在一个公正的世界里，如果有人发生了不幸，那一定是“事出有因”，因为宇宙是道德平衡的，世界是公正的，随机的不幸事件不会降临到无辜者头上。如果发生了一起恶性事件，那受害者肯定也有什么地方做得不对。表现出“公正世界假设”偏差的人，更倾向于责怪受害者。

这是为什么呢？因为他们找理由责怪受害者，能起到心理上的预防作用，帮助他们克服不可控的环境威胁所引发的焦虑。同时，还能安慰他们，让他们觉得自己将会受到公正待遇。

剑桥分析发现，“公正世界假设”跟种族偏见的关系最相关。在美国，很多白人比黑人富裕，文化程度比黑人高。相信“公正世界假设”的人认为，造成这种社会和经济差距的原因，要怪黑人自己，后者明明有那么多时间、条件可以迎头赶上，可就是扶不起来。针对这些人，剑桥分析会推送相关的叙事，强化他们的观念。

剑桥分析要做的第三条是煽动“黑暗三人格”。所谓的“黑暗三人格”，其中一个是自恋，极端以自我为中心；另一个是马基雅维利主义，就是为了达到目的不择手段，无情的利己主义；最后一个是情感抽离，不能跟人产生共情。一般来说，“黑暗三人格”都属于对社会适应不良，有这类人格障碍的人更可能作出反社会的行为。

脸书算法上有个特别的属性。如果一个人关注了大家都喜欢的电视剧，那么收到的新闻推送没什么变化。但如果他点赞了某个极端团体的帖子，算法就会把他和其他用户区别开来。此后，推荐引擎会优先给这个人推送一些极端话题，给他一些量身制作的新闻，脸书这样做是为了提高用户的参与度。对于脸书这样的社交媒体来说，用户参与度提升是一个重要的运营指标，参与度越高，看到广告的时间就越长。

社交媒体极度倚重用户参与度的提升，所以，他们会想办法利用一个人的弱点。最抓人眼球的内容，要么是恐怖的，要么就是让人发怒的。这是为什么？进化心理学家认为，人类要生存下去，对潜在威胁的关注度非常高，这是人的本性，所以，社交媒体特别喜欢激发人的不确定性。吓唬人可以变成一种生意。当然，光吓唬可不够，社交媒体还要给人建立期待，给一些奖励机制，吊起人们的胃口又让其捉摸不定，再给一些肤浅的娱乐。

2014年夏天，剑桥分析公司开始在脸书上投放虚假信息，创立一些群组。在这些群组中，他们会发布能进一步煽动和激怒用户的内容，等到群组到达一定规模，再组织线下活动，让这些人能交流彼此的偏执和恐惧。

剑桥分析观察到，当人们发怒时，对完整、理性的解释就没有多少需求了。愤怒能改变一个人的心态，人一旦愤怒，就想惩罚他人。“迁怒于人”，这是特别常见的心理现象，特别是迁怒于自己群体之外的人。发怒的人会低估不良后果的风险。换句话说，一个人被激发起怒气，就更容易被操控。

好，这就是第二部分的内容。剑桥分析要找到那些受政治正确所困的美国人，让他们意识到，政治正确是一种身份威胁。剑桥分析要强化人们的认知偏差，激发“黑暗三人格”。



好，《对不起，我操控了你的大脑》的精华内容已经为你解读完了。我们来回顾一下本期的知识要点。

第一，本书作者怀利在2013年加入SCL公司，当年10月见到了班农，11月获得大富翁默瑟的投资，SCL成为剑桥分析的母公司。剑桥分析从脸书获得了数千万人的数据，利用假新闻、假网站和群组活动来干扰用户的头脑，左右他们的判断。剑桥分析的总裁尼克斯、投资人默瑟，都把芸芸众生当作数据看待，喜欢高高在上的操控感。

第二，新闻媒体揭露了剑桥分析和SCL的行为后，两家公司启动了破产程序。公司发言人坚称他们没有违法，但公司行为被媒体曝光后，客户都跑掉了。剑桥分析到底如何干预了美国大选，如何操控了英国脱欧，这本书语焉不详，但怀利对公司非法获得数据、肮脏的心理战工具，都作出了有力的指控。

第三，剑桥分析注意到，许多美国人都觉得自己困居柜中，原来的优越感不复存在。他们要干的就是把这些人心中的仇恨和愤怒给勾出来，让他们感觉到自己的不适，受到了“政治正确”的限制。剑桥分析要让他们建立一个信念——种族关系是一场零和博弈，少数族裔拿走的东西越多，白人能拿到的就越少。别人主张政治正确，自己就无法发声。他们把政治正确界定为一种身份威胁，剑桥分析要做的是，强化特定人群的认知偏差，煽动其“黑暗三人格”。

第四，怀利的这本书能提醒人们，人很容易受到操控，我们根据可利用的信息做判断，但信息都是中转间接获得的，偏见可能会在不知不觉中被放大。现在，我们看到的很多内容都是被算法挑选过的，我们需要知道，算法的动机是吸引我们，要我们提供参与度，而不是给我们以启迪。

算法无处不在的时代，我们该怎么避免被操控呢？我想给你分享一下历史学家尤瓦尔·赫拉利的观点。他在《今日简史》这本书里说，技术是中性的，如果你知道自己想要什么，它能帮你达成目标。如果你不知道想要什么，就很容易被技术控制，由它来为你塑造目标。赫拉利给出的建议很简单，那就是认识你自己，不再跟着感觉走，而是了解自己最深层的情绪和欲望、了解自己想要达成的人生目标。跑在网络巨头和算法的前面，先认识自己，保留对自己、对人生的控制权。

以上，就是今天的全部内容。恭喜你，又听完了一本书！



### 划重点

 1. 人很容易被算法操控，偏见可能会在不知不觉中被放大，甚至会被激发出黑暗人格。避免被算法操控，首先要做的就是了解它如何运作。

 2. 技术是中性的，如果你知道自己想要什么，它能帮你达成目标。如果你不知道想要什么，就很容易被技术控制，由它来为你塑造目标。





